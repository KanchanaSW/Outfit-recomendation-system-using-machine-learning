{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16-FE-RF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2prZRTo0uIU7",
        "outputId": "530cbdd4-7ead-4039-ca59-10235ca099e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_file = \"/content/drive/MyDrive/FYP/datasetAG.zip\"\n",
        "train_file = \"/content/drive/MyDrive/FYP/dataset.zip\"\n",
        "\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(train_file, 'r') as z:\n",
        "    z.extractall()"
      ],
      "metadata": {
        "id": "vfn9FvVVuO8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import optimizers\n",
        "from keras.models import Model, Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import layers\n",
        "from keras import models\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "itH4WFcvuO5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        #rotation_range=10,\n",
        "        #width_shift_range=0.1,\n",
        "        #height_shift_range=0.1,\n",
        "        ##brightness_range=[0.4,0.7],\n",
        "        ##channel_shift_range=60.0,\n",
        "        #fill_mode='nearest',\n",
        "        #horizontal_flip=True\n",
        "        )\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'dataset/train',\n",
        "        target_size=(224, 224),  # all images will be resized to 224x224\n",
        "        batch_size=32,\n",
        "        color_mode='rgb',\n",
        "        class_mode='categorical')  # more than two classes\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        'dataset/validation',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        color_mode='rgb',\n",
        "        class_mode='categorical',\n",
        "        shuffle = False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bmLLrwDuOze",
        "outputId": "cf2e466c-92a1-40e0-f5de-bbb72ed81952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 903 images belonging to 3 classes.\n",
            "Found 150 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### RETRIVE TEST LABEL FROM GENERATOR ###\n",
        "\n",
        "train_num = train_generator.samples\n",
        "\n",
        "label_train = []\n",
        "train_images = []\n",
        "for i in range((train_num // train_generator.batch_size)+1):\n",
        "    X,y = train_generator.next()\n",
        "    label_train.append(y)\n",
        "    train_images.append(X)\n",
        "        \n",
        "label_train = np.argmax(np.vstack(label_train), axis=1)\n",
        "train_images = np.vstack(train_images)\n",
        "train_images = np.array(train_images)\n",
        "label_train = np.array(label_train)\n",
        "label_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kJq0CnuwrDW",
        "outputId": "ab8429de-0652-49a2-a757-045b6f5dfa3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(903,)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNOKSgXk2rxl",
        "outputId": "c4193591-137c-4550-a24b-e453658c1eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(903, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### RETRIVE TEST LABEL FROM GENERATOR ###\n",
        "\n",
        "test_num = validation_generator.samples\n",
        "\n",
        "label_test = []\n",
        "test_images = []\n",
        "for i in range((test_num // validation_generator.batch_size)+1):\n",
        "    X,y = validation_generator.next()\n",
        "    label_test.append(y)\n",
        "    test_images.append(X)\n",
        "        \n",
        "label_test = np.argmax(np.vstack(label_test), axis=1)\n",
        "test_images = np.vstack(test_images)\n",
        "test_images = np.array(test_images)\n",
        "label_test = np.array(label_test)\n",
        "label_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QC9v86g-xp8l",
        "outputId": "1b31e9c9-5b44-4821-ee8d-f35765c1a03a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150,)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Encode labels from text to integers.\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(label_test)\n",
        "test_labels_encoded = le.transform(label_test)\n",
        "le.fit(label_train)\n",
        "train_labels_encoded = le.transform(label_train)\n",
        "\n",
        "#Split data into test and train datasets (already split but assigning to meaningful convention)\n",
        "x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded\n",
        "\n",
        "###################################################################\n",
        "# Normalize pixel values to between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
      ],
      "metadata": {
        "id": "UampTYAyuOw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "VGG_model = VGG16(weights='imagenet',include_top=False,input_shape=(224, 224, 3))\n",
        "\n",
        "VGG_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_GcGwEJuOvu",
        "outputId": "ce28a1d3-0b03-4b96-9509-5d75650fd391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"This is the number of trainable weights before freezing the conv base:\", len(VGG_model.trainable_weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GDg5idNuOtw",
        "outputId": "cb2f3943-90f1-4915-a48a-1292d72caf39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable weights before freezing the conv base: 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VGG_model.trainable = False\n",
        "print(\"This is the number of trainable weights after freezing the conv base:\", len(VGG_model.trainable_weights))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wey5OKYzuOq-",
        "outputId": "54a9336d-23c1-4ca8-a9f7-e0db8fc7d74d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the number of trainable weights after freezing the conv base: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VGG_model.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in VGG_model.layers:\n",
        "    if layer.name == 'block5_conv1':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "VGG_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQf1PrCfuOoC",
        "outputId": "68c68bc1-3e56-413a-d214-8015ef7b5586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 7,079,424\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extract features using VGG imagenet weights\n",
        "#Train features\n",
        "train_feature_extractor=VGG_model.predict(x_train)\n",
        "train_features = train_feature_extractor.reshape(train_feature_extractor.shape[0], -1)\n",
        "#test features\n",
        "test_feature_extractor=VGG_model.predict(x_test)\n",
        "test_features = test_feature_extractor.reshape(test_feature_extractor.shape[0], -1)"
      ],
      "metadata": {
        "id": "LpDf0rxpuOk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################################\n",
        "#RANDOM FOREST implementation \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "RF_model = RandomForestClassifier(n_estimators = 150, random_state = 42)"
      ],
      "metadata": {
        "id": "3c5_CHEGuOh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on training data\n",
        "RF_model.fit(train_features, y_train) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xIHdheluOe9",
        "outputId": "59847635-8d9b-4cee-e1b0-aa399f27ff48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=150, random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_RF = RF_model.predict(test_features)\n",
        "#Inverse le transform to get original label back. \n",
        "prediction_RF = le.inverse_transform(prediction_RF)\n",
        "#Print overall accuracy\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report,mean_absolute_error,log_loss\n",
        "print (\"Accuracy = \", metrics.accuracy_score(label_test, prediction_RF))\n",
        "print (\"Loss : \",mean_absolute_error(label_test, prediction_RF))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4vH51cDuObl",
        "outputId": "522486b7-2dc9-43b7-9962-69c0073f2d0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy =  0.6866666666666666\n",
            "Loss :  0.35333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix - verify accuracy of each class\n",
        "from sklearn.metrics import confusion_matrix, classification_report,mean_absolute_error,log_loss\n",
        "import seaborn as sns\n",
        "cm = confusion_matrix(label_test, prediction_RF)\n",
        "#print(cm)\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Pp890qZJuOYd",
        "outputId": "ea4f49a4-0a3a-48ce-db79-2b73ba2ae1ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbea235de50>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the classification report for test data and predictions\n",
        "print (classification_report(label_test, prediction_RF))"
      ],
      "metadata": {
        "id": "xuOiCM4q55EV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f4196ef-db72-4163-e03b-bc59757a9c1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.72      0.69        50\n",
            "           1       0.71      0.50      0.59        50\n",
            "           2       0.80      0.98      0.88        50\n",
            "\n",
            "    accuracy                           0.73       150\n",
            "   macro avg       0.73      0.73      0.72       150\n",
            "weighted avg       0.73      0.73      0.72       150\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------"
      ],
      "metadata": {
        "id": "Yv5knY1eo3A4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN "
      ],
      "metadata": {
        "id": "tWFF2Y3Qn4gK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "knn.fit(train_features , y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe0U9TbzhIzA",
        "outputId": "582610c5-a305-43e6-9456-d80cd14f8491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_KNN = knn.predict(test_features)\n",
        "#Inverse le transform to get original label back. \n",
        "prediction_KNN = le.inverse_transform(prediction_KNN)\n",
        "#Print overall accuracy\n",
        "from sklearn import metrics\n",
        "print (\"Accuracy = \", metrics.accuracy_score(label_test, prediction_KNN))\n",
        "print (\"Loss : \",mean_absolute_error(label_test, prediction_KNN))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pqc8yc7AnSv5",
        "outputId": "63bca83d-2840-4778-bde6-6e4bc959fa8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy =  0.7933333333333333\n",
            "Loss :  0.23333333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix - verify accuracy of each class\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "cm = confusion_matrix(label_test, prediction_KNN)\n",
        "#print(cm)\n",
        "sns.heatmap(cm, annot=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "SwblZP-2oKDT",
        "outputId": "bbf8fdab-06d8-4faf-c6a7-68ba18294c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbea23a1410>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the classification report for test data and predictions\n",
        "print(classification_report(label_test, prediction_KNN))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACu8tR4sn885",
        "outputId": "a8d53205-4a82-40ae-cdc0-155b3cb6f727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.76      0.75        50\n",
            "           1       0.78      0.64      0.70        50\n",
            "           2       0.84      0.98      0.91        50\n",
            "\n",
            "    accuracy                           0.79       150\n",
            "   macro avg       0.79      0.79      0.79       150\n",
            "weighted avg       0.79      0.79      0.79       150\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9Vc0WAUEoA4x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}